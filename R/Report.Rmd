---
title: "kNN, Linear regression, and multilinear regression"
author: "Eduard Romero / Juan David Cepeda /  Carlos Bejarano"
date: "2023-04-18"
output: pdf_document
header-includes:
  - \usepackage{xcolor}
  - \usepackage{titling}
  - \pretitle{\begin{center}\Large\color{blue}\textbf}
  - \posttitle{\end{center}}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1.1 kNN, Linear regression, and multilinear regression

For the acquisition of our data, we will be using the Arduino micro controller with two sensors, an HC-SR04 ultrasonic sensor and the other an analog SHARP 0A41SK sensor.

The HC-SR04 ultrasonic sensor works by sending out high frequency sound waves and then measuring the time it takes for those sound waves to bounce back off of an object and return to the sensor. The sensor consists of two main components: a transmitter and a receiver.

## \textcolor{red}{Code Arduino for sensor Ultrasonic HC-SR04}

``` {echo="FALSE"}
# Pin digital 12 Trigger sensor
const int Trigger = 12;   
# Pin Digital 11 Echo sensor
const int Echo = 11;

void setup() {
  # Begin comunication Serial
  Serial.begin(9600);
  # Set pin as Output
  pinMode(Trigger, OUTPUT);
  # Set pin as Input
  pinMode(Echo, INPUT); 
  digitalWrite(Trigger, LOW);
}

void loop()
{
  # Variable for calculation time Echo
  long t; 

  digitalWrite(Trigger, HIGH);
  delayMicroseconds(10);
   # Send Pulse 10uS
  digitalWrite(Trigger, LOW);
  
  t = pulseIn(Echo, HIGH); 
  
  Serial.print("Time: ");
  Serial.print(t);      
  Serial.println();
  delay(2000);          
}
```

The Sharp GP2Y0A21 infrared sensor works by emitting an infrared (IR) beam and then measuring the distance to an object based on the reflection of that beam. The sensor consists of an IR emitter and a receiver.

## \textcolor{red}{Code Arduino for sensor SHARP GP2Y0A21}

``` {echo="FALSE"}
void setup() {
  // Comunicación seria a 9600 baudios
  Serial.begin(9600);
}

void loop() {
  // Leemos la entrada analógica 0 :
  int ADC_SHARP = analogRead(A0);
  Serial.println(ADC_SHARP);
  delay(10);
}
```

# 1.2 Predict Model

-   1.2.1 Pre-process your data (if required) and to perform an Exploratory Data Analysis.
-   1.2.2 Train a linear model per sensor to predict the distance detected by each sensor.

## \textcolor{red}{Analysis for the sensor ADC1 - ADC2}

```{r message=FALSE}
```


```{r message=FALSE}
# Import the librarys
library (tidyverse)
library (caret)
library(psych)
library(ggplot2)

folder <- dirname(rstudioapi::getSourceEditorContext()$path)
parentFolder <- dirname(folder)

#Read CSV File
Sensors1 <- read_csv(file = paste0(parentFolder, "/Datasets/Sensor.csv")) %>% as.data.frame()
#Show our Dataset Sensors1
Sensors1
# Give our a summary for variables ADC1 ADC2 And DISTANCE
summary(Sensors1)
# Histogram of the linear model ADC1
hist(Sensors1$ADC1,breaks = 100)
# Histogram of the linear model ADC2
hist(Sensors1$ADC2,breaks = 100)

pairs(Sensors1[-c(7,8)], pch = 21
, bg = c("red", "green3", "blue")[unclass(Sensors1$DISTANCE)])
# Select the corresponding columns
Data1 <- Sensors1[, c("DISTANCE", "ADC1")]
Data2 <- Sensors1[, c("DISTANCE", "ADC2")]
# Split data into training and test sets ADC1 - ADC2
set.seed(123)
trainIndex1 <- createDataPartition(Data1$DISTANCE, p = 0.8, list = FALSE)
trainData1 <- Data1[trainIndex1, ]
testData1 <- Data1[-trainIndex1, ]

trainIndex2 <- createDataPartition(Data2$DISTANCE, p = 0.8, list = FALSE)
trainData2 <- Data2[trainIndex2, ]
testData2 <- Data2[-trainIndex2, ]
# Train the linear model for distance and ADC1 - ADC2
Model1 <- lm(DISTANCE ~ ADC1, data = trainData1)
Model2 <- lm(DISTANCE ~ ADC2, data = trainData2)
# Evaluate model performance for distance and ADC1 - ADC2
predictions1 <- predict(Model1, newdata = testData1)
rmse1 <- sqrt(mean((predictions1 - testData1$DISTANCE)^2))
cat(sprintf("RMSE for DISTANCE y ADC1: %.2f\n", rmse1))
predictions2 <- predict(Model2, newdata = testData2)
rmse2 <- sqrt(mean((predictions2 - testData2$DISTANCE)^2))
cat(sprintf("RMSE for DISTANCE y ADC2: %.2f\n", rmse2))
```

> [!NOTE]
>
> An analysis of our predictors will be that the ADC1 sensor will have a better response to implement the ADC1 sensor. The value of RMSE closer to 0 will indicate a greater precision in the prediction of the implemented model.

-   1.2.4 Train a multilinear regression using the data from the 2 sensors to predict the distance to the wall.

```{r message=FALSE}

# Train multilinear regression model
AllModel <- lm(DISTANCE ~ ADC1 + ADC2, data = Sensors1)
# Predict using the trained model
predicted_values <- predict(AllModel, Sensors1)
# Evaluate model performance
rmse <- caret::RMSE(predicted_values, Sensors1$DISTANCE)
r_squared <- summary(AllModel)$r.squared
# Print model summary and evaluation metrics
print(summary(AllModel))
cat(paste0("RMSE: ", rmse, "\n"))
cat(paste0("R-squared: ", r_squared, "\n"))
```

-   1.2.5 Test the performance in your models by using cross-validation.

```{r message=FALSE}
#Cross-validation for Model 1 ADC1
set.seed(123)
Model1 <- train(DISTANCE ~ ADC1, data = Sensors1, method = "lm", trControl = trainControl(method = "cv", number = 10))
print(Model1)
#Cross-validation for Model 2 ADC2
set.seed(123)
Model2 <- train(DISTANCE ~ ADC2, data = Sensors1, method = "lm", trControl = trainControl(method = "cv", number = 10))
print(Model2)
```

# News prediction from the trainning Datasets

To predict the distance from a model we created the dataset PModel.CSV containing data from the ADC1 and ADC2 sensor and sampled every 100mm.

```{r message=FALSE}
PModel <- read_csv(file = paste0(parentFolder, "/Datasets/PModel.csv")) %>% as.data.frame()
#The head() function is very useful for getting a quick idea of the data in an object, especially if the object is large and you don't want to print the entire contents.
head(PModel)
#Summary of our Dataset
summary(PModel)
#create variable for predictions Firts Model
P1 <- predict(Model1,newdata=PModel)
print(P1)
#We plot the graph that relates the distance that is the predictor and the value of the ADC1 sensor.
ggplot(PModel, aes(x=ADC1, y=P1)) +
geom_point() +
geom_smooth(method='lm', formula=y~x, se=FALSE, col='dodgerblue1') +
theme_light()

#Create variable for predictions Second Model
P2 <- predict(Model2,newdata =PModel)
print(P2)
#We plot the graph that relates the distance that is the predictor and the value of the ADC2 sensor.
ggplot(PModel, aes(x=ADC2, y=P2)) +
geom_point() +
geom_smooth(method='lm', formula=y~x, se=FALSE, col='dodgerblue1') +
theme_light()
#Create variable for predictions model multilinear
P3 <- predict(AllModel,newdata =PModel)
print(P3)
#We plot the graph that relates the distance that is the predictor between the multi-linear model ADC1+ADC2.
ggplot(PModel, aes(x=ADC1+ADC2, y=P3)) +
geom_point() +
geom_smooth(method='lm', formula=y~x, se=FALSE, col='dodgerblue1') +
theme_light()

```

- 1.2.7 Discuss all your codes and results.

 * The sensor 1 ADC1 has a linear behavior, this is an ultrasonic sensor that works by mechanical waves, training our model we obtain that this is the best response to use it as a prediction model for our distance variable.
 
 * The sensor 2 ADC2 is a SHARP sensor of analog infrared operation, where its behavior is not linear, another characteristic of this sensor is the closer the object of detection, its variable will increase, it is inversely proportional to the distance.
 
 * We have two Datasets the first one called Sensors1 which contains values for the training for the 3 models,
the first model obtained a better response obtaining a RMSE value of 0.4127814 , which is an efficient predictor value to implement models for distance detection,

 * The second model obtained a non-optimal response with an RMSE value of 6.9711404, however by performing a better data analysis we can improve the efficiency of our model.

 * The third model is a multilinear model where we take into account both ADC1 and ADC2 sensors to make a distance prediction, the combination of these data gives us an RMSE of 0.34101 which tells us that the effectiveness of this combined model is good for predictions.

* After analyzing the graphs and values obtained from our models, Model 1 is the most optimal after training to predict our variable which in this case is distance.
 
*  RMSE is a measure of the average distance between the predicted and actual values, and it is calculated as the square root of the mean of the squared differences between the predicted and actual values.

* MAE is a measure of the average absolute difference between the predicted and actual values, and it is calculated as the mean of the absolute differences between the predicted and actual values. 

* R-squared (R²) is a statistical measure that represents the proportion of the variance in the dependent variable,ranges from 0 to 1, where 0 means that the model explains none of the variance and 1 means that the model explains all the variance.

## \textcolor{red}{Predictions of a categorical variable}

Develop a system (hardware and software) that includes the 2 sensors used in part 1. The system needs to let you
capture data that is useful to determine if a wall in front of the system is flat, convex, or concave. 

